{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for **\"Blind restoration of a JPEG-compressed image\"** and **\"Blind image denoising\"** figures. Select `fname` below to switch between the two.\n",
    "\n",
    "- To see overfitting set `num_iter` to a large value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "from models.skip2 import skip2\n",
    "from models.skip3 import skip3\n",
    "from models.residual import DilatedResidualNetwork\n",
    "from models import get_net\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from utils.denoising_utils import *\n",
    "\n",
    "# torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "# dtype = torch.DoubleTensor\n",
    "\n",
    "imsize =-1\n",
    "PLOT = True\n",
    "sigma = 25\n",
    "sigma_ = sigma/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deJPEG \n",
    "# fname = 'data/denoising/snail.jpg'\n",
    "\n",
    "## denoising\n",
    "# fname = '/home/semion/master_thesis/code/data/25/F16_GT.png'\n",
    "fname = '/home/semion/master_thesis/code/PGDIP/data/ref/house.png'\n",
    "# fname_noisy = '/home/semion/master_thesis/code/data/25/F16_noisy.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add synthetic noise\n",
    "img_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "img_np = pil_to_np(img_pil)\n",
    "\n",
    "# img_noisy_pil = crop_image(get_image(fname_noisy, imsize)[0], d=32)\n",
    "# img_noisy_np = pil_to_np(img_noisy_pil)\n",
    "\n",
    "img_noisy_pil, img_noisy_np = get_noisy_image(img_np, sigma_)\n",
    "\n",
    "if PLOT:\n",
    "    plot_image_grid([img_np, img_noisy_np], 4, 6);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'noise' # 'meshgrid'\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # 'net,input'\n",
    "\n",
    "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
    "# reg_noise_std = 1./20. # set to 1./20. for sigma=50\n",
    "LR = 0.01\n",
    "\n",
    "OPTIMIZER='adam' # 'LBFGS'\n",
    "show_every = 50\n",
    "\n",
    "\n",
    "num_iter = 1800\n",
    "# num_iter = 1\n",
    "# input_depth = 128 \n",
    "input_depth = 128\n",
    "figsize = 4 \n",
    "exp_weight=0.99\n",
    "\n",
    "# net = get_net(input_depth, 'skip', pad,\n",
    "#               skip_n33d=128, \n",
    "#               skip_n33u=128, \n",
    "#               skip_n11=[0, 4, 4, 4, 4], \n",
    "#               num_scales=5,\n",
    "#               upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "NSIZE = 5\n",
    "chdown = [128]*NSIZE\n",
    "# chdown = [128, 64, 32, 16, 8]\n",
    "chskip = [4]*NSIZE\n",
    "# chskip = [0]*NSIZE\n",
    "# chskip = [0, 0, 0, 0, 4]\n",
    "# chdown[0] = 128\n",
    "# chdown[-1] = 128\n",
    "# chskip[-1] = 4\n",
    "z_scale = 1e1\n",
    "\n",
    "ARCH = \"base\"\n",
    "# net = DilatedResidualNetwork(input_channels=3,\n",
    "#                             down_channels=chdown,\n",
    "#                             down_stride =[2]*NSIZE,\n",
    "#                             down_dilation = [1]*NSIZE).type(dtype)\n",
    "# net = skip3(input_depth, 3, num_channels_up = chdown, num_channels_skip=chskip,\n",
    "net = skip2(input_depth, 3, num_channels_up = chdown, num_channels_skip=chskip,\n",
    "# net = skip2(input_depth, 3, num_channels_up = [512, 256, 128, 64, 32, 16, 8], num_channels_skip=[4]*NSIZE,\n",
    "# net = skip2(input_depth, 3, num_channels_up = [10, 20], num_channels_skip=[1, 2],\n",
    "            upsample_mode='bilinear', need_sigmoid=True, need_bias=True, pad=pad, act_fun=\"LeakyReLU\").type(dtype)\n",
    "\n",
    "# net_input = get_noise(input_depth, INPUT, (img_pil.size[1]/2**NSIZE, img_pil.size[0]/2**NSIZE)).type(dtype).detach() * z_scale #000.0\n",
    "# net_input = get_noise(input_depth, INPUT, (img_pil.size[1]/2**2, img_pil.size[0]/2**2)).type(dtype).detach() * 10000 #000.0\n",
    "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0])).type(dtype).detach() * 1 #000.0\n",
    "# Compute number of parameters\n",
    "s  = sum([np.prod(list(p.size())) for p in net.parameters()]); \n",
    "print ('Number of params: %d' % s)\n",
    "# print(net)\n",
    "# Loss\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "img_noisy_var = np_to_torch(img_noisy_np).type(dtype)\n",
    "# net_input = img_noisy_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "out_avg = None\n",
    "last_net = None\n",
    "psrn_noisy_last = 0\n",
    "\n",
    "i = 0\n",
    "psnr = []\n",
    "def closure():\n",
    "    \n",
    "    global i, out_avg, psrn_noisy_last, last_net, psnr, net_input\n",
    "    \n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    \n",
    "    out = net(net_input)\n",
    "    \n",
    "    # Smoothing\n",
    "    if exp_weight is not None:\n",
    "        if out_avg is None:\n",
    "            out_avg = out.detach()\n",
    "        else:\n",
    "            out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "            \n",
    "    total_loss = mse(out, img_noisy_var)\n",
    "    total_loss.backward()\n",
    "        \n",
    "    \n",
    "    psrn_noisy = compare_psnr(img_noisy_np, out.detach().cpu().type(torch.FloatTensor).numpy()[0]) \n",
    "    psrn_gt    = compare_psnr(img_np, out.detach().cpu().type(torch.FloatTensor).numpy()[0]) \n",
    "    psrn_gt_sm = compare_psnr(img_np, out_avg.detach().cpu().type(torch.FloatTensor).numpy()[0]) \n",
    "    psnr.append(psrn_gt)\n",
    "    print ('Iteration %05d    Loss %f   PSNR_noisy: %f   PSRN_gt: %f PSNR_gt_sm: %f' % (i, total_loss.item(), psrn_noisy, psrn_gt, psrn_gt_sm), '\\r', end='')\n",
    "    if  PLOT and i % show_every == 0:\n",
    "        out_np = torch_to_np(out)\n",
    "        plot_image_grid([np.clip(out_np, 0, 1), np.clip(torch_to_np(out_avg), 0, 1)], factor=figsize, nrow=1)\n",
    "        plt.plot(psnr)\n",
    "        \n",
    "    \n",
    "    # Backtracking\n",
    "    if i % show_every:\n",
    "        if psrn_noisy - psrn_noisy_last < -5: \n",
    "            print('Falling back to previous checkpoint.')\n",
    "\n",
    "            for new_param, net_param in zip(last_net, net.parameters()):\n",
    "                net_param.data.copy_(new_param.cuda())\n",
    "\n",
    "            return total_loss*0\n",
    "        else:\n",
    "            last_net = [x.data.cpu() for x in net.parameters()]\n",
    "            psrn_noisy_last = psrn_noisy\n",
    "            \n",
    "    i += 1\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "\n",
    "plt.plot(psnr)\n",
    "plt.savefig(\"psnr_{}_{}_{}_{}_{}.png\".format(ARCH, chdown, chskip, z_scale, LR))\n",
    "print(torch.cuda.max_memory_allocated()/1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np = var_to_np(net(net_input))\n",
    "q = plot_image_grid([np.clip(out_np, 0, 1), img_np], factor=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch norm, nocudnn: max 31.97, 1800: 31.15\n",
    "* instance norm, nocudnn: max 32.19, 1800: 32.19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
