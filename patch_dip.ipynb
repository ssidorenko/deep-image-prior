{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for **\"Blind restoration of a JPEG-compressed image\"** and **\"Blind image denoising\"** figures. Select `fname` below to switch between the two.\n",
    "\n",
    "- To see overfitting set `num_iter` to a large value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "from models import *\n",
    "from models.skip_deep import skip_deep\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from utils.denoising_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "# torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "# dtype = torch.DoubleTensor\n",
    "\n",
    "imsize =-1\n",
    "PLOT = True\n",
    "sigma = 25\n",
    "sigma_ = sigma/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deJPEG \n",
    "# fname = 'data/denoising/snail.jpg'\n",
    "\n",
    "## denoising\n",
    "# fname = '/home/semion/master_thesis/code/data/25/F16_GT.png'\n",
    "# fname = '/home/semion/master_thesis/code/data/25/kodim02_GT.png'\n",
    "# fname = '/home/semion/master_thesis/code/PGDIP/data/denoising/IM\n",
    "fname = '/home/semion/master_thesis/code/PGDIP/data/ref/house.png'\n",
    "# fname = './grid_hex.png'\n",
    "# fname_noisy = '/home/semion/master_thesis/code/data/25/F16_noisy.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add synthetic noise\n",
    "orig_img_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "orig_img_np = pil_to_np(orig_img_pil)\n",
    "\n",
    "# img_noisy_pil = crop_image(get_image(fname_noisy, imsize)[0], d=32)\n",
    "# img_noisy_np = pil_to_np(img_noisy_pil)\n",
    "\n",
    "orig_img_noisy_pil, orig_img_noisy_np = get_noisy_image(orig_img_np, sigma_)\n",
    "\n",
    "if PLOT:\n",
    "    plot_image_grid([orig_img_np, orig_img_noisy_np], 4, 6);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'noise' # 'meshgrid'\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # 'net,input'\n",
    "\n",
    "# reg_noise_std = 1./300. # set to 1./20. for sigma=50\n",
    "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
    "LR = 0.01\n",
    "\n",
    "OPTIMIZER='adam' # 'LBFGS'\n",
    "show_every = 100\n",
    "\n",
    "\n",
    "num_iter = 4000\n",
    "# num_iter = 1\n",
    "input_depth = 32 \n",
    "figsize = 12 \n",
    "exp_weight=0.9\n",
    "scales = 5\n",
    "\n",
    "# patch_size = 128\n",
    "patch_size = 128\n",
    "patch_stride = 16\n",
    "# fade_size = 8\n",
    "\n",
    "# make sure patch size and stride match image dimensions\n",
    "assert float(int((orig_img_np.shape[1] - patch_size)/patch_stride)) == (orig_img_np.shape[1] - patch_size)/patch_stride\n",
    "assert float(int((orig_img_np.shape[2] - patch_size)/patch_stride)) == (orig_img_np.shape[2] - patch_size)/patch_stride\n",
    "\n",
    "patch_x_n = int((orig_img_np.shape[1] - patch_size)/patch_stride + 1)\n",
    "patch_y_n = int((orig_img_np.shape[2] - patch_size)/patch_stride + 1)\n",
    "\n",
    "patches = []\n",
    "for x in range(0, patch_x_n):\n",
    "    patch_row = []\n",
    "    for y in range(0, patch_y_n):\n",
    "        start_time = datetime.datetime.now()\n",
    "#         x_start = max(x * patch_stride - fade_size, 0)\n",
    "#         x_end = min(patch_size + x * patch_stride + fade_size, orig_img_np.shape[1])\n",
    "#         y_start = max(y * patch_stride - fade_size, 0)\n",
    "#         y_end = min(patch_size + y * patch_stride + fade_size, orig_img_np.shape[2])\n",
    "        x_start = x * patch_stride\n",
    "        x_end = patch_size + x * patch_stride\n",
    "        y_start = y * patch_stride\n",
    "        y_end = y * patch_stride + patch_size\n",
    "        \n",
    "        img_noisy_np = orig_img_noisy_np[:,x_start:x_end, y_start:y_end]\n",
    "        img_np = orig_img_np[:,x_start:x_end, y_start:y_end]\n",
    "        \n",
    "        # plot_image_grid(patches, nrow = 9)\n",
    "        depth = 32\n",
    "        net = skip_deep(input_depth, 3, num_channels_down = [8]*depth,\n",
    "                                                    num_channels_up =   [8]*depth,\n",
    "                                                    num_channels_skip = [4]*depth,\n",
    "                                                    filter_size_down=3,\n",
    "                                                    filter_size_up=3,\n",
    "                                                    upsample_mode='bilinear', downsample_mode='stride',\n",
    "                                                    need_sigmoid=True, need_bias=True, pad=pad, act_fun=\"LeakyReLU\").type(dtype)\n",
    "\n",
    "        net_input = get_noise(input_depth, INPUT, (img_np.shape[1], img_np.shape[2])).type(dtype).detach() * 1 #000.0\n",
    "        # net_input = img_noisy_var\n",
    "        # Compute number of parameters\n",
    "        s  = sum([np.prod(list(p.size())) for p in net.parameters()]); \n",
    "        print ('Number of params: %d' % s)\n",
    "\n",
    "        # Loss\n",
    "        mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "        img_noisy_var = np_to_torch(img_noisy_np).type(dtype)\n",
    "        # print(net)\n",
    "\n",
    "        # Optimize\n",
    "\n",
    "        net_input_saved = net_input.detach().clone()\n",
    "        noise = net_input.detach().clone()\n",
    "        out_avg = None\n",
    "        last_net = None\n",
    "        psrn_noisy_last = 0\n",
    "\n",
    "        i = 0\n",
    "        psnr = []\n",
    "        def closure():\n",
    "\n",
    "            global i, out_avg, psrn_noisy_last, last_net, psnr\n",
    "\n",
    "            if reg_noise_std > 0:\n",
    "                net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "\n",
    "            out = net(net_input)\n",
    "\n",
    "            # Smoothing\n",
    "            if exp_weight is not None:\n",
    "                if out_avg is None:\n",
    "                    out_avg = out.detach()\n",
    "                else:\n",
    "                    out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
    "\n",
    "            total_loss = mse(out, img_noisy_var)\n",
    "            total_loss.backward()\n",
    "\n",
    "\n",
    "            psrn_noisy = compare_psnr(img_noisy_np, out.detach().cpu().type(torch.FloatTensor).numpy()[0]) \n",
    "            psrn_gt    = compare_psnr(img_np, out.detach().cpu().type(torch.FloatTensor).numpy()[0]) \n",
    "            psrn_gt_sm = compare_psnr(img_np, out_avg.detach().cpu().type(torch.FloatTensor).numpy()[0]) \n",
    "            psnr.append(psrn_gt)\n",
    "            print ('Iteration %05d    Loss %f   PSNR_noisy: %f   PSRN_gt: %f PSNR_gt_sm: %f' % (i, total_loss.item(), psrn_noisy, psrn_gt, psrn_gt_sm), '\\r', end='')\n",
    "            if  PLOT and ((i % show_every == 0) or (i == num_iter - 1)):\n",
    "                out_np = torch_to_np(out)\n",
    "                plot_image_grid([\n",
    "                    np.clip(out_np, 0, 1), np.clip(torch_to_np(out_avg), 0, 1),\n",
    "                    np.clip(img_noisy_np, 0, 1), np.clip(img_np, 0, 1)\n",
    "                ], factor=figsize, nrow=4, interpolation=None)\n",
    "                plt.plot(psnr)\n",
    "\n",
    "\n",
    "            # Backtracking\n",
    "            if i % show_every:\n",
    "                if psrn_noisy - psrn_noisy_last < -5: \n",
    "                    print('Falling back to previous checkpoint.')\n",
    "\n",
    "                    for new_param, net_param in zip(last_net, net.parameters()):\n",
    "                        net_param.data.copy_(new_param.cuda())\n",
    "\n",
    "                    return total_loss*0\n",
    "                else:\n",
    "                    last_net = [x.data.cpu() for x in net.parameters()]\n",
    "                    psrn_noisy_last = psrn_noisy\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            return total_loss\n",
    "\n",
    "        p = get_params(OPT_OVER, net, net_input)\n",
    "        optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "        print(\"finished, time: {}\".format(datetime.datetime.now() - start_time))\n",
    "        patch_row.append(out_avg)\n",
    "    patches.append(patch_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.zeros(1, 3, orig_img_np.shape[1], orig_img_np.shape[2]).type(dtype)\n",
    "out_counter = torch.zeros(1, 3, orig_img_np.shape[1], orig_img_np.shape[2]).type(dtype)\n",
    "\n",
    "fade_1d = torch.linspace(0.0, 1.0, patch_stride).type(dtype)\n",
    "rev_fade_1d = torch.linspace(1.0, 0.0, patch_stride).type(dtype)\n",
    "print(fade_1d.shape)\n",
    "x_fade_2d = fade_1d.unsqueeze(1).expand(1, 3, patch_stride, patch_size)\n",
    "x_rev_fade_2d = rev_fade_1d.unsqueeze(1).expand(1, 3, patch_stride, patch_size)\n",
    "print(x_fade_2d.shape)\n",
    "y_fade_2d = fade_1d.expand(1, 3, patch_size, patch_stride)\n",
    "y_rev_fade_2d = rev_fade_1d.expand(1, 3, patch_size, patch_stride)\n",
    "\n",
    "for x in range(patch_x_n):\n",
    "    for y in range(patch_y_n):\n",
    "        x_start = x * patch_stride\n",
    "        x_end = patch_size + x * patch_stride\n",
    "        y_start = y * patch_stride\n",
    "        y_end = y * patch_stride\n",
    "        \n",
    "        fade_matrix = torch.ones(*patches[x][y].shape).type(dtype)\n",
    "        if x != 0:\n",
    "            fade_matrix[:,:,:patch_stride,:] *= x_fade_2d\n",
    "        if x != patch_x_n - 1:\n",
    "            fade_matrix[:,:,-patch_stride:,:] *= x_rev_fade_2d\n",
    "        if y != 0:\n",
    "            fade_matrix[:,:,:,:patch_stride] *= y_fade_2d\n",
    "        if y != patch_y_n - 1:\n",
    "            fade_matrix[:,:,:,-patch_stride:] *= y_rev_fade_2d\n",
    "        \n",
    "        \n",
    "        out[:,:,x * patch_stride:patch_size + x*patch_stride,y * patch_stride:patch_size + y*patch_stride] += fade_matrix * patches[x][y]\n",
    "        out_counter[:,:,x * patch_stride:patch_size + x*patch_stride,y * patch_stride:patch_size + y*patch_stride] += fade_matrix\n",
    "out /= out_counter\n",
    "\n",
    "print(torch.cuda.max_memory_allocated()/1024**2)\n",
    "# out_np = var_to_np(net(net_input))\n",
    "q = plot_image_grid([np.clip(torch_to_np(out), 0, 1)], factor=8);\n",
    "compare_psnr(orig_img_np, torch_to_np(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch norm, nocudnn: max 31.97, 1800: 31.15\n",
    "* instance norm, nocudnn: max 32.19, 1800: 32.19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_noisy_var - out_avg\n",
    "q = plot_image_grid([\n",
    "    img_np,\n",
    "    img_noisy_np,\n",
    "    (img_noisy_np-img_np)*1,\n",
    "#     img_noisy_np,\n",
    "    np.clip(torch_to_np(out_avg), 0, 1),\n",
    "    np.clip((img_np - torch_to_np(out_avg))*1, 0, 1),\n",
    "    np.clip((img_noisy_np - torch_to_np(out_avg))*1, 0, 1),\n",
    "    ], factor=13, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fade_1d = torch.linspace(0.0, 1.0, patch_stride)\n",
    "# print(fade_1d.expand(1, 3, 4, 16))\n",
    "# print(fade_1d.unsqueeze(1).expand(1, 3, 16, 4))\n",
    "fade_1d = torch.linspace(0.0, 1.0, patch_stride)\n",
    "rev_fade_1d = torch.linspace(1.0, 0.0, patch_stride)\n",
    "print(fade_1d.shape)\n",
    "x_fade_2d = fade_1d.expand(1, 3, 16, 4)\n",
    "# x_rev_fade_2d = rev_fade_1d.expand(1, 3, patch_stride, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
